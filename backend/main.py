import os
import sys
import re
from pathlib import Path
from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from dotenv import load_dotenv
import requests
from PIL import Image
import io
import base64
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load environment variables from C:\dev\.env for local development
# In production (Render), environment variables are set in the dashboard
env_path = Path(r'C:\dev\.env')

# Only load .env file if it exists (for local development)
if env_path.exists():
    load_dotenv(env_path)
    print(f"üîç Loading .env from: {env_path}")
    print(f"‚úÖ .env file exists: {env_path.exists()}")
else:
    print("üåê Running in production mode - using environment variables from hosting platform")

# Get API keys
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
GOOGLE_SPEECH_API_KEY = os.getenv("GOOGLE_SPEECH_API_KEY")
GEMINI_API_URL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro:generateContent"

if GOOGLE_SPEECH_API_KEY:
    print(f"üîë Google Speech API Key loaded: {GOOGLE_SPEECH_API_KEY[:15]}...")
else:
    print("‚ùå Google Speech API Key not found!")

if GEMINI_API_KEY:
    print(f"üîë Gemini API Key loaded: {GEMINI_API_KEY[:15]}...")
else:
    print("‚ùå Gemini API Key not found!")

if not GOOGLE_SPEECH_API_KEY or not GEMINI_API_KEY:
    print(f"‚ùå Error: API keys not found in {env_path}")
    print("Please ensure your .env file exists at C:\\dev\\.env with:")
    print("GOOGLE_SPEECH_API_KEY=your_key_here")
    print("GEMINI_API_KEY=your_key_here")
    raise ValueError("Missing required API keys in .env file")

app = FastAPI(
    title="HASIRI Agricultural Assistant API",
    description="AI-powered agricultural assistant for farmers with automatic language detection",
    version="2.0.0"
)

# Configure CORS for Flutter web/app deployment
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Allow all origins for development
    allow_credentials=True,
    allow_methods=["GET", "POST", "HEAD"],
    allow_headers=["*"],
)

def clean_text_for_tts(text: str) -> str:
    """
    Clean text for Text-to-Speech to avoid pronunciation of symbols and formatting.
    Removes markdown formatting, bullet points, and other symbols that TTS might pronounce.
    """
    if not text:
        return ""
    
    # Remove markdown formatting
    text = re.sub(r'\*\*([^*]+)\*\*', r'\1', text)  # Bold **text**
    text = re.sub(r'\*([^*]+)\*', r'\1', text)      # Italic *text*
    text = re.sub(r'__([^_]+)__', r'\1', text)      # Bold __text__
    text = re.sub(r'_([^_]+)_', r'\1', text)        # Italic _text_
    text = re.sub(r'`([^`]+)`', r'\1', text)        # Code `text`
    text = re.sub(r'```[^`]*```', '', text)         # Code blocks
    
    # Remove bullet points and list markers
    text = re.sub(r'^[\s]*[‚Ä¢¬∑‚ñ™‚ñ´‚Ä£‚ÅÉ]\s*', '', text, flags=re.MULTILINE)  # Unicode bullets
    text = re.sub(r'^[\s]*[-*+]\s*', '', text, flags=re.MULTILINE)     # ASCII bullets
    text = re.sub(r'^[\s]*\d+\.\s*', '', text, flags=re.MULTILINE)     # Numbered lists
    
    # Remove headers
    text = re.sub(r'^#+\s*', '', text, flags=re.MULTILINE)             # Markdown headers
    
    # Remove links
    text = re.sub(r'\[([^\]]+)\]\([^)]+\)', r'\1', text)               # [text](url)
    text = re.sub(r'https?://[^\s]+', '', text)                        # Raw URLs
    
    # Remove common symbols that might be pronounced
    text = re.sub(r'[#@$%^&*(){}[\]|\\<>]', '', text)                  # Special characters
    text = re.sub(r'[‚Üí‚Üê‚Üë‚Üì‚üπ‚ü∏‚ü∑]', '', text)                             # Arrow symbols
    text = re.sub(r'[‚úì‚úó‚úò‚úî‚úï]', '', text)                                # Check marks
    text = re.sub(r'[¬©¬Æ‚Ñ¢]', '', text)                                   # Copyright symbols
    text = re.sub(r'[¬∞‚ÑÉ‚Ñâ]', ' degrees ', text)                         # Temperature symbols
    text = re.sub(r'[‚Çπ$¬£‚Ç¨¬•]', '', text)                                 # Currency symbols
    
    # Clean up excessive punctuation
    text = re.sub(r'[.]{2,}', '.', text)                               # Multiple dots
    text = re.sub(r'[-]{2,}', '-', text)                               # Multiple dashes
    text = re.sub(r'[!]{2,}', '!', text)                               # Multiple exclamations
    text = re.sub(r'[?]{2,}', '?', text)                               # Multiple questions
    
    # Replace common separators with natural pauses
    text = re.sub(r'[-‚Äì‚Äî]', ', ', text)                                 # Dashes to commas
    text = re.sub(r'[|]', ', ', text)                                   # Pipes to commas
    text = re.sub(r'[/]', ' or ', text)                                 # Slashes to "or"
    
    # Handle common abbreviations that might be mispronounced
    text = re.sub(r'\b(etc\.?)\b', 'and so on', text, flags=re.IGNORECASE)
    text = re.sub(r'\b(i\.e\.?)\b', 'that is', text, flags=re.IGNORECASE)
    text = re.sub(r'\b(e\.g\.?)\b', 'for example', text, flags=re.IGNORECASE)
    text = re.sub(r'\b(vs\.?)\b', 'versus', text, flags=re.IGNORECASE)
    
    # Clean up whitespace
    text = re.sub(r'\s+', ' ', text)                                    # Multiple spaces
    text = re.sub(r'\n\s*\n', '\n', text)                              # Multiple newlines
    text = text.strip()                                                 # Leading/trailing spaces
    
    return text

def detect_language_from_text(text: str) -> str:
    """
    Fallback function to detect language from text patterns when Speech API doesn't provide it.
    """
    if not text:
        return "en-US"
    
    text_lower = text.lower()
    
    # Check for Hindi script (Devanagari)
    if re.search(r'[\u0900-\u097F]', text):
        return "hi-IN"
    
    # Check for Tamil script
    if re.search(r'[\u0B80-\u0BFF]', text):
        return "ta-IN"
    
    # Check for Telugu script
    if re.search(r'[\u0C00-\u0C7F]', text):
        return "te-IN"
    
    # Check for Kannada script
    if re.search(r'[\u0C80-\u0CFF]', text):
        return "kn-IN"
    
    # Check for Malayalam script
    if re.search(r'[\u0D00-\u0D7F]', text):
        return "ml-IN"
    
    # Check for Bengali script
    if re.search(r'[\u0980-\u09FF]', text):
        return "bn-IN"
    
    # Check for Gujarati script
    if re.search(r'[\u0A80-\u0AFF]', text):
        return "gu-IN"
    
    # Check for Punjabi script (Gurmukhi)
    if re.search(r'[\u0A00-\u0A7F]', text):
        return "pa-IN"
    
    # Check for Marathi vs Hindi (both use Devanagari)
    if re.search(r'[\u0900-\u097F]', text):
        hindi_words = ['‡§π‡•à', '‡§î‡§∞', '‡§ï‡§æ', '‡§ï‡•Ä', '‡§ï‡•ã', '‡§Æ‡•á‡§Ç', '‡§∏‡•á', '‡§™‡§∞', '‡§ï‡•á', '‡§Ø‡§π', '‡§µ‡§π']
        marathi_words = ['‡§Ü‡§π‡•á', '‡§Ü‡§£‡§ø', '‡§ö‡§æ', '‡§ö‡•Ä', '‡§≤‡§æ', '‡§Æ‡§ß‡•ç‡§Ø‡•á', '‡§™‡§æ‡§∏‡•Ç‡§®', '‡§µ‡§∞', '‡§π‡§æ', '‡§§‡•ã']
        
        hindi_count = sum(1 for word in hindi_words if word in text_lower)
        marathi_count = sum(1 for word in marathi_words if word in text_lower)
        
        if marathi_count > hindi_count:
            return "mr-IN"
        else:
            return "hi-IN"
    
    # Check for common Tamil words written in English transliteration
    tamil_words = ['vanakkam', 'nandri', 'payan', 'arisi', 'vivasayam', 'tamil', 'seyyalama', 'aruvadai']
    if any(word in text_lower for word in tamil_words):
        return "ta-IN"
    
    # Check for common Hindi words in transliteration
    hindi_transliteration = ['kaise', 'kahan', 'kya', 'namaste', 'dhanyawad', 'krishi', 'fasal']
    if any(word in text_lower for word in hindi_transliteration):
        return "hi-IN"
    
    # Check for other language words in transliteration
    if any(word in text_lower for word in ['telugu', 'ela', 'enti', 'bagundi']):
        return "te-IN"
    
    if any(word in text_lower for word in ['kannada', 'hege', 'yaava', 'chennu']):
        return "kn-IN"
    
    # Default to English
    return "en-US"
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Change to your frontend URL in production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Root endpoint for health check - support both GET and HEAD
@app.get("/")
@app.head("/")
async def root():
    return {
        "message": "HASIRI Agricultural Assistant API",
        "status": "active",
        "version": "2.0.0",
        "features": ["automatic language detection", "native speaker responses"],
        "endpoints": [
            "/chat",
            "/speech-to-text", 
            "/text-to-speech",
            "/analyze-image"
        ]
    }

# Health check endpoint
@app.get("/health")
async def health_check():
    return {"status": "healthy", "timestamp": "2025-07-27"}

# Test endpoint for debugging connections
@app.get("/test")
async def test_connection():
    return {
        "message": "Connection successful!",
        "backend": "Render",
        "api_keys_loaded": bool(GEMINI_API_KEY and GOOGLE_SPEECH_API_KEY),
        "cors_enabled": True,
        "features": ["automatic language detection", "native speaker responses"]
    }

# Simple POST test endpoint
@app.post("/test-post")
async def test_post(message: str = Form("Hello from frontend!")):
    return {
        "received": message,
        "response": "Backend received your message successfully!",
        "status": "working"
    }

# Speech-to-Text endpoint with automatic language detection
@app.post("/speech-to-text")
async def speech_to_text(audio: UploadFile = File(...)):
    try:
        print(f"üé§ Processing speech-to-text for file: {audio.filename}")
        audio_bytes = await audio.read()
        
        headers = {"Content-Type": "application/json"}
        stt_url = f"https://speech.googleapis.com/v1/speech:recognize?key={GOOGLE_SPEECH_API_KEY}"
        
        # Enhanced configuration for automatic language detection
        data = {
            "config": {
                "encoding": "WEBM_OPUS",  # Updated for web audio
                "sampleRateHertz": 48000,  # Updated sample rate for web audio
                "languageCode": "en-US",  # Primary language hint
                "alternativeLanguageCodes": [
                    "ta-IN",    # Tamil
                    "hi-IN",    # Hindi  
                    "te-IN",    # Telugu
                    "kn-IN",    # Kannada
                    "ml-IN",    # Malayalam
                    "bn-IN",    # Bengali
                    "gu-IN",    # Gujarati
                    "pa-IN",    # Punjabi
                    "mr-IN"     # Marathi
                ],
                "enableAutomaticPunctuation": True,
                "enableWordConfidence": True,
                "enableSpokenPunctuation": True,
                "enableWordTimeOffsets": True,
                "audioChannelCount": 1,
                "model": "latest_long"
            },
            "audio": {
                "content": base64.b64encode(audio_bytes).decode("utf-8")
            }
        }
        
        response = requests.post(stt_url, headers=headers, json=data)
        print(f"üîç Speech API response status: {response.status_code}")
        
        # Debug: Print the full response to understand the structure
        if response.ok:
            result = response.json()
            print(f"üîç Full Speech API response: {result}")
        else:
            print(f"‚ùå Speech API error response: {response.text}")
        
        if response.ok:
            result = response.json()
            transcript = ""
            detected_language = "en-US"  # Default fallback
            
            if "results" in result and result["results"]:
                # Get the best alternative from results
                best_result = result["results"][0]
                alt = best_result["alternatives"][0]
                transcript = alt["transcript"]
                
                # Try multiple ways to get detected language from Google Speech API
                detected_language = None
                
                # Method 1: Check if language_code is in the result metadata
                if "languageCode" in best_result:
                    detected_language = best_result["languageCode"]
                    print(f"üåê Language detected from result metadata: {detected_language}")
                
                # Method 2: Check alternative's language_code
                elif "languageCode" in alt:
                    detected_language = alt["languageCode"]
                    print(f"üåê Language detected from alternative: {detected_language}")
                
                # Method 3: Check if it's in the response root
                elif "languageCode" in result:
                    detected_language = result["languageCode"]
                    print(f"üåê Language detected from response root: {detected_language}")
                
                # If Google Speech API didn't return language, use our text-based detection
                if not detected_language:
                    detected_language = detect_language_from_text(transcript)
                    print(f"üß† Using text-based language detection: {detected_language}")
                else:
                    print(f"üåê Google Speech API detected language: {detected_language}")
                
                print(f"‚úÖ Transcription successful: {transcript[:50]}...")
                print(f"üåê Final detected language: {detected_language}")
            else:
                print("‚ö†Ô∏è No speech detected in audio")
                # Still try to detect language from any available text
                if transcript:
                    detected_language = detect_language_from_text(transcript)
            
            return {
                "transcript": transcript, 
                "languageCode": detected_language,
                "language_code": detected_language  # Also include this for frontend compatibility
            }
        else:
            print(f"‚ùå Speech API error: {response.text}")
            return {"error": response.text}
            
    except Exception as e:
        print(f"‚ùå Speech-to-text error: {str(e)}")
        return {"error": f"Processing error: {str(e)}"}

# Text-to-Speech endpoint
@app.post("/text-to-speech")
async def text_to_speech(text: str = Form(...), languageCode: str = Form("en-US")):
    try:
        print(f"üîä Processing text-to-speech")
        print(f"üåê Using languageCode: {languageCode}")
        print(f"üìù Original text length: {len(text)} characters")
        
        # Clean text to remove symbols and formatting that TTS might pronounce
        cleaned_text = clean_text_for_tts(text)
        print(f"üßπ Cleaned text length: {len(cleaned_text)} characters")
        
        headers = {"Content-Type": "application/json"}
        tts_url = f"https://texttospeech.googleapis.com/v1/text:synthesize?key={GOOGLE_SPEECH_API_KEY}"
        
        # Handle long text by truncating intelligently
        tts_text = cleaned_text
        if len(cleaned_text.encode('utf-8')) > 4500:  # Conservative limit to avoid 5000 byte limit
            print(f"‚ö†Ô∏è Text too long for TTS ({len(cleaned_text.encode('utf-8'))} bytes), truncating...")
            
            # Try to find natural break points (sentences)
            sentences = cleaned_text.split('‡•§')  # Hindi sentence separator
            if len(sentences) == 1:
                sentences = cleaned_text.split('.')  # English sentence separator
            
            if len(sentences) > 1:
                # Take first few sentences that fit within limit
                tts_text = ""
                for sentence in sentences:
                    test_text = tts_text + sentence + "‡•§" if tts_text else sentence
                    if len(test_text.encode('utf-8')) < 4500:
                        tts_text = test_text
                    else:
                        break
                
                if not tts_text:  # Fallback if even first sentence is too long
                    tts_text = cleaned_text[:1000] + "..."
            else:
                # Simple truncation if no sentence breaks found
                tts_text = cleaned_text[:1000] + "..."
            
            print(f"‚úÇÔ∏è TTS text truncated to {len(tts_text.encode('utf-8'))} bytes")
        
        # Select appropriate voice based on language
        voice_config = {"languageCode": languageCode, "ssmlGender": "FEMALE"}
        
        # Use specific voice names for Indian languages for better quality
        voice_names = {
            "ta-IN": "ta-IN-Standard-A",  # Tamil female voice
            "hi-IN": "hi-IN-Standard-A",  # Hindi female voice
            "te-IN": "te-IN-Standard-A",  # Telugu female voice
            "kn-IN": "kn-IN-Standard-A",  # Kannada female voice
            "ml-IN": "ml-IN-Standard-A",  # Malayalam female voice
            "bn-IN": "bn-IN-Standard-A",  # Bengali female voice
            "gu-IN": "gu-IN-Standard-A",  # Gujarati female voice
            "pa-IN": "pa-IN-Standard-A",  # Punjabi female voice
            "mr-IN": "mr-IN-Standard-A",  # Marathi female voice
            "en-US": "en-US-Standard-C",  # English female voice
        }
        
        if languageCode in voice_names:
            voice_config["name"] = voice_names[languageCode]
            print(f"üé≠ Using voice: {voice_names[languageCode]}")
        else:
            print(f"üé≠ Using default voice for: {languageCode}")
        
        data = {
            "input": {"text": tts_text},
            "voice": voice_config,
            "audioConfig": {"audioEncoding": "MP3"}
        }
        
        response = requests.post(tts_url, headers=headers, json=data)
        print(f"üîç TTS response status: {response.status_code}")
        
        if response.ok:
            result = response.json()
            audio_content = result.get("audioContent", "")
            print(f"‚úÖ TTS successful, audio content length: {len(audio_content)} chars")
            return {"audioContent": audio_content}
        else:
            print(f"‚ùå TTS error: {response.text}")
            return {"error": response.text}
            
    except Exception as e:
        print(f"‚ùå Text-to-speech error: {str(e)}")
        return {"error": f"Processing error: {str(e)}"}

# Chat endpoint with native speaker responses
@app.post("/chat")
async def chat(text: str = Form(...), languageCode: str = Form("en-US")):
    try:
        # Extract language part (e.g., 'ta' from 'ta-IN')
        language = languageCode.split('-')[0]
        
        print(f"üí¨ Processing chat request")
        print(f"üåê Detected languageCode: {languageCode}")
        print(f"ÔøΩ Extracted language: {language}")
        print(f"ÔøΩüìù User message: {text[:100]}...")
        
        headers = {"Content-Type": "application/json"}
        params = {"key": GEMINI_API_KEY}
        
        # Map language codes to language names for better AI understanding
        language_names = {
            "ta": "Tamil",
            "hi": "Hindi", 
            "te": "Telugu",
            "kn": "Kannada",
            "ml": "Malayalam",
            "bn": "Bengali",
            "gu": "Gujarati",
            "pa": "Punjabi",
            "mr": "Marathi",
            "en": "English"
        }
        
        language_name = language_names.get(language, "English")
        
        # Native speaker context based on language
        native_context = {
            "ta": "‡Æ®‡ØÄ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æí‡Æ∞‡ØÅ ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç ‡Æµ‡Æø‡Æµ‡Æö‡Ææ‡ÆØ‡Æø ‡ÆÆ‡Æ±‡Øç‡Æ±‡ØÅ‡ÆÆ‡Øç ‡Æµ‡Æø‡Æµ‡Æö‡Ææ‡ÆØ ‡Æ®‡Æø‡Æ™‡ØÅ‡Æ£‡Æ∞‡Øç. ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç‡Æ®‡Ææ‡Æü‡Øç‡Æü‡Æø‡Æ©‡Øç ‡Æâ‡Æ≥‡Øç‡Æ≥‡ØÇ‡Æ∞‡Øç ‡Æµ‡Æø‡Æµ‡Æö‡Ææ‡ÆØ ‡ÆÆ‡ØÅ‡Æ±‡Øà‡Æï‡Æ≥‡Øç, ‡Æ™‡ÆØ‡Æø‡Æ∞‡Øç‡Æï‡Æ≥‡Øç, ‡ÆÆ‡Æ±‡Øç‡Æ±‡ØÅ‡ÆÆ‡Øç ‡Æö‡ØÇ‡Æ¥‡Øç‡Æ®‡Æø‡Æ≤‡Øà‡Æï‡Æ≥‡Øà ‡Æ®‡Æ©‡Øç‡Æï‡ØÅ ‡Æ§‡ØÜ‡Æ∞‡Æø‡Æ®‡Øç‡Æ§‡Æµ‡Æ∞‡Øç.",
            "hi": "‡§Ü‡§™ ‡§è‡§ï ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§ï‡§ø‡§∏‡§æ‡§® ‡§î‡§∞ ‡§ï‡•É‡§∑‡§ø ‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û ‡§π‡•à‡§Ç‡•§ ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§ñ‡•á‡§§‡•Ä, ‡§´‡§∏‡§≤‡•ã‡§Ç ‡§î‡§∞ ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§™‡§∞‡§ø‡§∏‡•ç‡§•‡§ø‡§§‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡•Ä ‡§ó‡§π‡§∞‡•Ä ‡§∏‡§Æ‡§ù ‡§∞‡§ñ‡§§‡•á ‡§π‡•à‡§Ç‡•§",
            "te": "‡∞Æ‡±Ä‡∞∞‡±Å ‡∞í‡∞ï ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞∞‡±à‡∞§‡±Å ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞µ‡±ç‡∞Ø‡∞µ‡∞∏‡∞æ‡∞Ø ‡∞®‡∞ø‡∞™‡±Å‡∞£‡±Å‡∞°‡±Å. ‡∞Ü‡∞Ç‡∞ß‡±ç‡∞∞‡∞™‡±ç‡∞∞‡∞¶‡±á‡∞∂‡±ç ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞§‡±Ü‡∞≤‡∞Ç‡∞ó‡∞æ‡∞£ ‡∞µ‡±ç‡∞Ø‡∞µ‡∞∏‡∞æ‡∞Ø ‡∞™‡∞¶‡±ç‡∞ß‡∞§‡±Å‡∞≤‡∞®‡±Å ‡∞¨‡∞æ‡∞ó‡∞æ ‡∞§‡±Ü‡∞≤‡±Å‡∞∏‡±Å.",
            "kn": "‡≤®‡≥Ä‡≤µ‡≥Å ‡≤ï‡≤®‡≥ç‡≤®‡≤° ‡≤∞‡≥à‡≤§ ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤ï‡≥É‡≤∑‡≤ø ‡≤§‡≤ú‡≥ç‡≤û. ‡≤ï‡≤∞‡≥ç‡≤®‡≤æ‡≤ü‡≤ï‡≤¶ ‡≤∏‡≥ç‡≤•‡≤≥‡≥Ä‡≤Ø ‡≤ï‡≥É‡≤∑‡≤ø ‡≤µ‡≤ø‡≤ß‡≤æ‡≤®‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤ö‡≥Ü‡≤®‡≥ç‡≤®‡≤æ‡≤ó‡≤ø ‡≤§‡≤ø‡≤≥‡≤ø‡≤¶‡≤ø‡≤¶‡≥ç‡≤¶‡≥Ä‡≤∞‡≤ø.",
            "ml": "‡¥®‡¥ø‡¥ô‡µç‡¥ô‡µæ ‡¥í‡¥∞‡µÅ ‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥ø ‡¥ï‡µº‡¥∑‡¥ï‡¥®‡µÅ‡¥Ç ‡¥ï‡¥æ‡µº‡¥∑‡¥ø‡¥ï ‡¥µ‡¥ø‡¥¶‡¥ó‡µç‡¥ß‡¥®‡µÅ‡¥Æ‡¥æ‡¥£‡µç. ‡¥ï‡µá‡¥∞‡¥≥‡¥§‡µç‡¥§‡¥ø‡¥®‡µç‡¥±‡µÜ ‡¥™‡µç‡¥∞‡¥æ‡¥¶‡µá‡¥∂‡¥ø‡¥ï ‡¥ï‡¥æ‡µº‡¥∑‡¥ø‡¥ï ‡¥∞‡µÄ‡¥§‡¥ø‡¥ï‡µæ ‡¥®‡¥®‡µç‡¥®‡¥æ‡¥Ø‡¥ø ‡¥Ö‡¥±‡¥ø‡¥Ø‡¥æ‡¥Ç.",
            "bn": "‡¶Ü‡¶™‡¶®‡¶ø ‡¶è‡¶ï‡¶ú‡¶® ‡¶¨‡¶æ‡¶ô‡¶æ‡¶≤‡¶ø ‡¶ï‡ßÉ‡¶∑‡¶ï ‡¶è‡¶¨‡¶Ç ‡¶ï‡ßÉ‡¶∑‡¶ø ‡¶¨‡¶ø‡¶∂‡ßá‡¶∑‡¶ú‡ßç‡¶û‡•§ ‡¶™‡¶∂‡ßç‡¶ö‡¶ø‡¶Æ‡¶¨‡¶ô‡ßç‡¶ó ‡¶ì ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂‡ßá‡¶∞ ‡¶∏‡ßç‡¶•‡¶æ‡¶®‡ßÄ‡¶Ø‡¶º ‡¶ï‡ßÉ‡¶∑‡¶ø ‡¶™‡¶¶‡ßç‡¶ß‡¶§‡¶ø ‡¶≠‡¶æ‡¶≤‡ßã ‡¶ú‡¶æ‡¶®‡ßá‡¶®‡•§",
            "gu": "‡™§‡™Æ‡´á ‡™è‡™ï ‡™ó‡´Å‡™ú‡™∞‡™æ‡™§‡´Ä ‡™ñ‡´á‡™°‡´Ç‡™§ ‡™Ö‡™®‡´á ‡™ï‡´É‡™∑‡™ø ‡™®‡™ø‡™∑‡´ç‡™£‡™æ‡™§ ‡™õ‡´ã. ‡™ó‡´Å‡™ú‡™∞‡™æ‡™§‡™®‡´Ä ‡™∏‡´ç‡™•‡™æ‡™®‡™ø‡™ï ‡™ï‡´É‡™∑‡™ø ‡™™‡™¶‡´ç‡™ß‡™§‡™ø‡™ì ‡™∏‡™æ‡™∞‡´Ä ‡™∞‡´Ä‡™§‡´á ‡™ú‡™æ‡™£‡´ã ‡™õ‡´ã‡•§",
            "pa": "‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®á‡©±‡®ï ‡®™‡©∞‡®ú‡®æ‡®¨‡©Ä ‡®ï‡®ø‡®∏‡®æ‡®® ‡®Ö‡®§‡©á ‡®ñ‡©á‡®§‡©Ä‡®¨‡®æ‡©ú‡©Ä ‡®Æ‡®æ‡®π‡®ø‡®∞ ‡®π‡©ã‡•§ ‡®™‡©∞‡®ú‡®æ‡®¨ ‡®¶‡©á ‡®∏‡®•‡®æ‡®®‡®ï ‡®ñ‡©á‡®§‡©Ä‡®¨‡®æ‡©ú‡©Ä ‡®¶‡©á ‡®§‡®∞‡©Ä‡®ï‡®ø‡®Ü‡®Ç ‡®®‡©Ç‡©∞ ‡®ö‡©∞‡®ó‡©Ä ‡®§‡®∞‡©ç‡®π‡®æ‡®Ç ‡®ú‡®æ‡®£‡®¶‡©á ‡®π‡©ã‡•§",
            "mr": "‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä ‡§è‡§ï ‡§Æ‡§∞‡§æ‡§†‡•Ä ‡§∂‡•á‡§§‡§ï‡§∞‡•Ä ‡§Ü‡§£‡§ø ‡§ï‡•É‡§∑‡•Ä ‡§§‡§ú‡•ç‡§û ‡§Ü‡§π‡§æ‡§§. ‡§Æ‡§π‡§æ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§∏‡•ç‡§•‡§æ‡§®‡§ø‡§ï ‡§∂‡•á‡§§‡•Ä ‡§™‡§¶‡•ç‡§ß‡§§‡•Ä ‡§ö‡§æ‡§Ç‡§ó‡§≤‡•ç‡§Ø‡§æ ‡§Æ‡§æ‡§π‡•Ä‡§§ ‡§Ü‡§π‡•á‡§§‡•§",
            "en": "You are an experienced Indian farmer and agricultural expert familiar with diverse farming practices across India."
        }
        
        # Enhanced agricultural context with VERY strict native speaker enforcement
        native_intro = native_context.get(language, native_context["en"])
        
        prompt = (
            f"{native_intro} "
            f"‡§Ü‡§™‡§ï‡•ã ‡§Ö‡§™‡§®‡•Ä ‡§Æ‡§æ‡§§‡•É‡§≠‡§æ‡§∑‡§æ {language_name} ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§ï‡§ø‡§∏‡§æ‡§® ‡§ï‡•Ä ‡§§‡§∞‡§π ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•á‡§®‡§æ ‡§π‡•à‡•§ "
            f"CRITICAL: ‡§Ü‡§™‡§ï‡§æ ‡§™‡•Ç‡§∞‡§æ ‡§â‡§§‡•ç‡§§‡§∞ ‡§ï‡•á‡§µ‡§≤ {language_name} ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•á‡§Ç ‡§π‡•ã‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è‡•§ "
            f"‡§ï‡§ø‡§∏‡•Ä ‡§≠‡•Ä ‡§Ö‡§®‡•ç‡§Ø ‡§≠‡§æ‡§∑‡§æ ‡§ï‡§æ ‡§è‡§ï ‡§≠‡•Ä ‡§∂‡§¨‡•ç‡§¶ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§® ‡§ï‡§∞‡•á‡§Ç‡•§ "
            f"‡§Ü‡§™ ‡§è‡§ï ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø {language_name} ‡§ï‡§ø‡§∏‡§æ‡§® ‡§π‡•à‡§Ç, ‡§µ‡§ø‡§¶‡•á‡§∂‡•Ä ‡§®‡§π‡•Ä‡§Ç‡•§ "
            f"‡§∏‡§∞‡§≤, ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§π‡§æ‡§∞‡§ø‡§ï ‡§î‡§∞ ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞‡•Ä‡§Ø ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§™‡•ç‡§∞‡§æ‡§∏‡§Ç‡§ó‡§ø‡§ï ‡§ï‡•É‡§∑‡§ø ‡§∏‡§≤‡§æ‡§π ‡§¶‡•á‡§Ç‡•§ "
            f"‡§§‡•Å‡§∞‡§Ç‡§§ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§®‡•ç‡§µ‡§ø‡§§ ‡§ï‡§ø‡§è ‡§ú‡§æ ‡§∏‡§ï‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§ï‡§¶‡§Æ‡•ã‡§Ç ‡§™‡§∞ ‡§ß‡•ç‡§Ø‡§æ‡§® ‡§¶‡•á‡§Ç‡•§ "
            f"‡§´‡§∏‡§≤, ‡§Æ‡•å‡§∏‡§Æ, ‡§ï‡•Ä‡§ü, ‡§∞‡•ã‡§ó, ‡§â‡§∞‡•ç‡§µ‡§∞‡§ï, ‡§∏‡§ø‡§Ç‡§ö‡§æ‡§à, ‡§∏‡§∞‡§ï‡§æ‡§∞‡•Ä ‡§Ø‡•ã‡§ú‡§®‡§æ‡§è‡§Ç, ‡§¨‡§æ‡§ú‡§æ‡§∞ ‡§≠‡§æ‡§µ, ‡§ú‡•à‡§µ‡§ø‡§ï ‡§ñ‡•á‡§§‡•Ä, ‡§î‡§∞ ‡§Æ‡•å‡§∏‡§Æ‡•Ä ‡§∏‡§≤‡§æ‡§π ‡§ú‡•à‡§∏‡•á ‡§µ‡§ø‡§∑‡§Ø‡•ã‡§Ç ‡§ï‡•ã ‡§ï‡§µ‡§∞ ‡§ï‡§∞‡•á‡§Ç‡•§ "
            f"‡§π‡§Æ‡•á‡§∂‡§æ ‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡•á ‡§™‡•ç‡§∞‡§§‡§ø ‡§â‡§§‡•ç‡§∏‡§æ‡§π‡§ú‡§®‡§ï ‡§î‡§∞ ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§∞‡§π‡•á‡§Ç‡•§ "
            f"TTS ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§∞‡§≤ ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç, ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§™‡•ç‡§∞‡§§‡•Ä‡§ï ‡§Ø‡§æ ‡§¨‡•Å‡§≤‡•á‡§ü ‡§™‡•â‡§á‡§Ç‡§ü ‡§® ‡§≤‡§ó‡§æ‡§è‡§Ç‡•§ "
            f"‡§¨‡•Å‡§≤‡•á‡§ü ‡§™‡•â‡§á‡§Ç‡§ü ‡§ï‡•á ‡§¨‡§ú‡§æ‡§Ø ‡§®‡§Ç‡§¨‡§∞ ‡§µ‡§æ‡§≤‡•Ä ‡§∏‡•Ç‡§ö‡•Ä ‡§Ø‡§æ ‡§™‡•à‡§∞‡§æ‡§ó‡•ç‡§∞‡§æ‡§´ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç‡•§ "
            f"‡§Ø‡§æ‡§¶ ‡§∞‡§ñ‡•á‡§Ç: ‡§Ü‡§™‡§ï‡§æ ‡§™‡•Ç‡§∞‡§æ ‡§ú‡§µ‡§æ‡§¨ ‡§ï‡•á‡§µ‡§≤ {language_name} ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•á‡§Ç ‡§π‡•ã‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è‡•§ ‡§ï‡•ã‡§à ‡§Ö‡§Ç‡§ó‡•ç‡§∞‡•á‡§ú‡•Ä ‡§∂‡§¨‡•ç‡§¶ ‡§®‡§π‡•Ä‡§Ç‡•§ "
            f"‡§ï‡§ø‡§∏‡§æ‡§® ‡§ï‡§æ ‡§∏‡§Ç‡§¶‡•á‡§∂: {text}"
        )
        
        data = {
            "contents": [
                {"role": "user", "parts": [{"text": prompt}]}
            ]
        }
        
        response = requests.post(GEMINI_API_URL, headers=headers, params=params, json=data)
        print(f"üîç Gemini response status: {response.status_code}")
        
        if response.ok:
            result = response.json()
            reply = result.get("candidates", [{}])[0].get("content", {}).get("parts", [{}])[0].get("text", "")
            print(f"‚úÖ Chat response generated: {reply[:100]}...")
            return {"reply": reply}
        else:
            print(f"‚ùå Gemini error: {response.text}")
            return {"reply": "Sorry, I couldn't process your request. Please try again."}
            
    except Exception as e:
        print(f"‚ùå Chat error: {str(e)}")
        return {"reply": "I'm having trouble right now. Please try again in a moment."}

# Image analysis endpoint with native language support
@app.post("/analyze-image")
async def analyze_image(
    file: UploadFile = File(...),
    prompt: str = Form("Analyze this crop image for diseases, pests, growth stage, and provide farming advice"),
    languageCode: str = Form("en-US")
):
    try:
        # Extract language part (e.g., 'ta' from 'ta-IN')
        language = languageCode.split('-')[0]
        
        print(f"üì∏ Processing image analysis for file: {file.filename}")
        print(f"üìù Analysis prompt: {prompt[:100]}...")
        print(f"üåê Image analysis languageCode: {languageCode}")
        print(f"üî§ Extracted language: {language}")
        
        headers = {"Content-Type": "application/json"}
        params = {"key": GEMINI_API_KEY}
        
        image_bytes = await file.read()
        print(f"üìä Image size: {len(image_bytes)} bytes")
        
        # Detect MIME type, fallback to image/jpeg if unknown
        mime_type = file.content_type
        if not mime_type or mime_type == "application/octet-stream":
            # Try to guess from file extension
            if file.filename and file.filename.lower().endswith(".png"):
                mime_type = "image/png"
            elif file.filename and file.filename.lower().endswith(".jpg"):
                mime_type = "image/jpeg"
            elif file.filename and file.filename.lower().endswith(".jpeg"):
                mime_type = "image/jpeg"
            else:
                mime_type = "image/jpeg"  # Default fallback
        
        print(f"üñºÔ∏è Detected MIME type: {mime_type}")
        
        image_base64 = base64.b64encode(image_bytes).decode("utf-8")
        
        # Map language codes to language names for better AI understanding
        language_names = {
            "ta": "Tamil",
            "hi": "Hindi", 
            "te": "Telugu",
            "kn": "Kannada",
            "ml": "Malayalam",
            "bn": "Bengali",
            "gu": "Gujarati",
            "pa": "Punjabi",
            "mr": "Marathi",
            "en": "English"
        }
        
        language_name = language_names.get(language, "English")
        
        # Native speaker context for image analysis
        native_context = {
            "ta": "‡Æ®‡ØÄ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æí‡Æ∞‡ØÅ ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç ‡Æµ‡Æø‡Æµ‡Æö‡Ææ‡ÆØ‡Æø ‡ÆÆ‡Æ±‡Øç‡Æ±‡ØÅ‡ÆÆ‡Øç ‡Æ™‡ÆØ‡Æø‡Æ∞‡Øç ‡Æ®‡Øã‡ÆØ‡Øç ‡Æ®‡Æø‡Æ™‡ØÅ‡Æ£‡Æ∞‡Øç. ",
            "hi": "‡§Ü‡§™ ‡§è‡§ï ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§ï‡§ø‡§∏‡§æ‡§® ‡§î‡§∞ ‡§´‡§∏‡§≤ ‡§∞‡•ã‡§ó ‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û ‡§π‡•à‡§Ç‡•§ ",
            "te": "‡∞Æ‡±Ä‡∞∞‡±Å ‡∞í‡∞ï ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞∞‡±à‡∞§‡±Å ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞™‡∞Ç‡∞ü ‡∞µ‡±ç‡∞Ø‡∞æ‡∞ß‡∞ø ‡∞®‡∞ø‡∞™‡±Å‡∞£‡±Å‡∞°‡±Å‡•§ ",
            "kn": "‡≤®‡≥Ä‡≤µ‡≥Å ‡≤ï‡≤®‡≥ç‡≤®‡≤° ‡≤∞‡≥à‡≤§ ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤¨‡≥Ü‡≤≥‡≥Ü ‡≤∞‡≥ã‡≤ó ‡≤§‡≤ú‡≥ç‡≤û‡•§ ",
            "ml": "‡¥®‡¥ø‡¥ô‡µç‡¥ô‡µæ ‡¥í‡¥∞‡µÅ ‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥ø ‡¥ï‡µº‡¥∑‡¥ï‡¥®‡µÅ‡¥Ç ‡¥µ‡¥ø‡¥≥ ‡¥∞‡µã‡¥ó ‡¥µ‡¥ø‡¥¶‡¥ó‡µç‡¥ß‡¥®‡µÅ‡¥Æ‡¥æ‡¥£‡µç‡•§ ",
            "bn": "‡¶Ü‡¶™‡¶®‡¶ø ‡¶è‡¶ï‡¶ú‡¶® ‡¶¨‡¶æ‡¶ô‡¶æ‡¶≤‡¶ø ‡¶ï‡ßÉ‡¶∑‡¶ï ‡¶è‡¶¨‡¶Ç ‡¶´‡¶∏‡¶≤‡ßá‡¶∞ ‡¶∞‡ßã‡¶ó ‡¶¨‡¶ø‡¶∂‡ßá‡¶∑‡¶ú‡ßç‡¶û‡•§ ",
            "gu": "‡™§‡™Æ‡´á ‡™è‡™ï ‡™ó‡´Å‡™ú‡™∞‡™æ‡™§‡´Ä ‡™ñ‡´á‡™°‡´Ç‡™§ ‡™Ö‡™®‡´á ‡™™‡™æ‡™ï ‡™∞‡´ã‡™ó ‡™®‡™ø‡™∑‡´ç‡™£‡™æ‡™§ ‡™õ‡´ã‡•§ ",
            "pa": "‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®á‡©±‡®ï ‡®™‡©∞‡®ú‡®æ‡®¨‡©Ä ‡®ï‡®ø‡®∏‡®æ‡®® ‡®Ö‡®§‡©á ‡®´‡®∏‡®≤ ‡®∞‡©ã‡®ó ‡®Æ‡®æ‡®π‡®ø‡®∞ ‡®π‡©ã‡•§ ",
            "mr": "‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä ‡§è‡§ï ‡§Æ‡§∞‡§æ‡§†‡•Ä ‡§∂‡•á‡§§‡§ï‡§∞‡•Ä ‡§Ü‡§£‡§ø ‡§™‡•Ä‡§ï ‡§∞‡•ã‡§ó ‡§§‡§ú‡•ç‡§û ‡§Ü‡§π‡§æ‡§§‡•§ ",
            "en": "You are an experienced Indian farmer and crop disease specialist. "
        }
        
        native_intro = native_context.get(language, native_context["en"])
        
        # Enhanced prompt for better crop analysis with native speaker enforcement
        enhanced_prompt = (
            f"{native_intro}"
            f"CRITICAL INSTRUCTION: Your response must be written ENTIRELY in {language_name} language ONLY. "
            f"DO NOT write even a single word in English or any other language. "
            f"Start your response immediately in {language_name} without any English introduction. "
            f"Analyze this crop image and provide in {language_name} language: "
            f"1. Crop identification (if possible) "
            f"2. Disease detection (symptoms, causes, treatment) "
            f"3. Pest identification (if visible) "
            f"4. Growth stage assessment "
            f"5. Soil/environmental conditions visible "
            f"6. Recommended actions for the farmer "
            f"7. Prevention tips for future "
            f"Be specific, practical, and provide actionable advice in {language_name} language as a native speaker. "
            f"Use simple text without special symbols, bullet points, or formatting as your response will be converted to speech. "
            f"Instead of bullet points, use numbered lists or paragraphs. "
            f"Remember: Write your ENTIRE response in {language_name} language only. No English words allowed. "
            f"User's specific request: {prompt}"
        )
        
        data = {
            "contents": [
                {
                    "role": "user",
                    "parts": [
                        {"text": enhanced_prompt},
                        {
                            "inline_data": {
                                "mime_type": mime_type,
                                "data": image_base64
                            }
                        }
                    ]
                }
            ]
        }
        
        response = requests.post(GEMINI_API_URL, headers=headers, params=params, json=data)
        print(f"üîç Image analysis response status: {response.status_code}")
        
        if response.ok:
            result = response.json()
            reply = result.get("candidates", [{}])[0].get("content", {}).get("parts", [{}])[0].get("text", "")
            print(f"‚úÖ Image analysis completed: {reply[:100]}...")
            return {"reply": reply}
        else:
            print(f"‚ùå Image analysis error: {response.text}")
            return {"reply": "Sorry, I couldn't analyze this image. Please try with a clearer crop image."}
            
    except Exception as e:
        print(f"‚ùå Image analysis error: {str(e)}")
        return {"reply": "I'm having trouble analyzing this image. Please try again with a different image."}

if __name__ == "__main__":
    import uvicorn
    port = int(os.environ.get("PORT", 8000))
    print("üöÄ Starting HASIRI Backend Server...")
    print(f"üìÅ Using .env file from: {env_path.absolute()}")
    print(f"üåê Server will be available at: http://localhost:{port}")
    print(f"üìã API Endpoints:")
    print(f"   ‚Ä¢ POST /chat - Chat with AI assistant")
    print(f"   ‚Ä¢ POST /speech-to-text - Convert speech to text")
    print(f"   ‚Ä¢ POST /text-to-speech - Convert text to speech")
    print(f"   ‚Ä¢ POST /analyze-image - Analyze crop images")
    uvicorn.run(app, host="0.0.0.0", port=port)